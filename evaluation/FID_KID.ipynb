{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FID & KID computation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy 10k CHOLECT45 data from https://github.com/CAMMA-public/cholect45 to dest_path. \n",
    "### Comment out cells below if you need to prepare a folder with real data.\n",
    "### Copy with margin becasue some frames are all black. Exclude videos 01, 49, 25, 66, 52, 56.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, shutil\n",
    "# import random \n",
    "# import glob\n",
    "# from tqdm import tqdm\n",
    "# import random\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from torchvision.transforms import functional as F\n",
    "# from torchvision.transforms import InterpolationMode\n",
    "# import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:28<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# n=10500 #draw more to exclude all black frames\n",
    "\n",
    "# cholect_path = '/path/to/real_data'\n",
    "# dest_path = 'dest/path/to/real_data'\n",
    "# os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "# items=[vid for vid in os.listdir(cholect_path) if all(t not in vid for t in ['01', '49', '25', '66', '52', '56']) ]\n",
    "\n",
    "# for i in tqdm(items):\n",
    "#     imgs = [img for img in os.listdir(os.path.join(cholect_path, i)) if \".png\" in img]\n",
    "#     frames_to_sample = n//len(items)\n",
    "#     imgs = random.sample(imgs, frames_to_sample+1)\n",
    "#     for img in imgs:\n",
    "#         src_path = os.path.join(cholect_path, i, img)\n",
    "#         out_path = os.path.join(dest_path, str(i +\"_\" + img))\n",
    "#         shutil.copy(src_path, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove black frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10530/10530 [01:37<00:00, 107.88it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def is_almost_black(image_path, threshold=10):\n",
    "#     \"\"\"\n",
    "#     Check if an image is almost black by comparing pixel values with a threshold.\n",
    "#     \"\"\"\n",
    "#     image = Image.open(image_path).convert('L')  # Open the image and convert it to grayscale\n",
    "#     pixels = image.getdata()\n",
    "#     for pixel in pixels:\n",
    "#         if pixel > threshold:\n",
    "#             return False\n",
    "#     return True\n",
    "\n",
    "# def remove_black_images(folder_path):\n",
    "#     \"\"\"\n",
    "#     Remove black and almost black images from a folder.\n",
    "#     \"\"\"\n",
    "#     for filename in tqdm(os.listdir(folder_path)):\n",
    "#         if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust the file extensions as needed\n",
    "#             image_path = os.path.join(folder_path, filename)\n",
    "#             if is_almost_black(image_path):\n",
    "#                 os.remove(image_path)\n",
    "\n",
    "# # Example usage\n",
    "# remove_black_images(dest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove excessive images to keep equal 10k needed for FID, KID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_list = os.listdir(dest_path)\n",
    "# files_to_delete = random.sample(file_list, len(file_list) - 10000)\n",
    "\n",
    "# for file_name in files_to_delete:\n",
    "#     file_path = os.path.join(dest_path, file_name)\n",
    "#     os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize and crop images, save to separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [06:53<00:00, 24.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# dest_path_cropped = dest_path +\"_cropped\"\n",
    "\n",
    "# os.makedirs(folder_cropped, exist_ok=True)\n",
    "\n",
    "# for filename in tqdm.tqdm(os.listdir(dest_path)):\n",
    "#     if filename.endswith('.jpeg') or filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "#         # Open the image file\n",
    "#         image = Image.open(os.path.join(dest_path, filename)).convert(\"RGB\")\n",
    "#         image = transforms.Resize(299)(image)\n",
    "#         image = transforms.CenterCrop(299)(image)\n",
    "#         # Save the cropped image with the same name as the original\n",
    "#         image.save(os.path.join(dest_path_cropped, filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate FID and KID \n",
    "### We first resize synthetic images to 299 and copy them to tmp folder - we always do it that way to have unified pipeline (resizing impacts fid & kid values, we want to have full control)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch-fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import glob\n",
    "import torch_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_path = 'path/to/real/data/cropped' # dest_path_cropped from previous cells\n",
    "data_path_25_66 = '/path/to/data' #output_vid25_66\n",
    "data_path_01_49 = '/path/to/data' #output_vid01_49\n",
    "data_path_52_56 = '/path/to/data' #output_vid52_56\n",
    "\n",
    "# calculate FID & KID for mixed style\n",
    "rand_dict = {1: data_path_25_66,\n",
    "            2: data_path_01_49,\n",
    "            3: data_path_52_56}\n",
    "\n",
    "filenames_common =set(os.listdir(rand_dict[1]))& set(os.listdir(rand_dict[2])) & set(os.listdir(rand_dict[3]))\n",
    "filenames = [os.path.join(rand_dict[random.randint(1, 3)], f) for f in filenames_common]\n",
    "\n",
    "random.seed(420420)\n",
    "filenames = random.sample(filenames,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save images in a tmp folder. It is important to keep exactly the same resizing method.\n",
    "tmp_folder = \"/path/to/tmp/folder\"\n",
    "\n",
    "if os.path.exists(tmp_folder):\n",
    "    shutil.rmtree(tmp_folder)\n",
    "os.makedirs(tmp_folder, exist_ok=True)\n",
    "\n",
    "for filename in tqdm.tqdm(filenames):\n",
    "    if filename.endswith('.jpeg') or filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "        # Open the image file\n",
    "        image = Image.open(os.path.join(filename)).convert(\"RGB\")\n",
    "        image = transforms.Resize(299)(image)\n",
    "        # Save the cropped image with the same name as the original\n",
    "        image.save(os.path.join(tmp_folder, os.path.basename(filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate FID and KID\n",
    "metrics_dict = torch_fidelity.calculate_metrics(\n",
    "    input1=real_data_path,\n",
    "    input2=tmp_folder, \n",
    "    cuda=True, \n",
    "    isc=False, \n",
    "    fid=True, \n",
    "    kid=True, \n",
    "    prc=False, \n",
    "    verbose=True,\n",
    "    kid_subset_size =1000,\n",
    "    cache = False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
